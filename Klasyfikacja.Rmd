---
title: "Klasyfikacja nadzorowana"
author: "Krzysztof Dyba"
output:
  html_document:
    toc: yes
    toc_float: true
date: 02.12.2022 r.
---

## Wczytanie danych

Procedura wczytania danych wygląda identycznie tak jak w poprzednim przypadku.

```{r message=FALSE}
library("terra")
```

```{r}
files = list.files("dane/landsat", pattern = "\\.TIF$", full.names = TRUE)
landsat = rast(files)
names(landsat) = paste0("B", 1:7)
```

```{r}
poly = vect("dane/powiat_sremski.gpkg")
```

Jednak tym razem dodatkowo wczytamy raster z klasami pokrycia terenu
([Sentinel-2 Global Land Cover](https://s2glc.cbk.waw.pl/)).

```{r}
cat = rast("dane/S2GLC_T33UXT.tif")
cat
```

Prosta wizualizacja klas pokrycia terenu.

```{r}
plot(cat, type = "classes")
```

Klasy przedstawione są jako ID, co nie jest dla nas zbyt przydatne. Oprócz danych
rastrowych, musimy wczytać jeszcze tabelę atrybutów, która znajduje się w osobnym
pliku `S2GLC_T33UXT.csv`. Możemy to zrobić za pomocą funkcji `read.csv()`.

```{r}
leg = read.csv("dane/S2GLC_T33UXT.csv")
head(leg)
```

W pierwszej kolumnie znajduje się ID klasy, w drugiej wartość koloru RGB w
zapisie szesnastkowym, w trzeciej nazwa klasy.

## Operacje na rastrach

Jak można zauważyć, nasze rastry różnią się rozdzielczością przestrzenną (scena 
Landsat ma 30 m, natomiast klasy pokrycia terenu 10 m). Kiedy rastry posiadają
różne rozdzielczości, to nie jest możliwe wykonywanie na nich operacji matematycznych.
W takim przypadku musimy sprowadzić je do jednakowej rozdzielczości. Ten
proces nazywa się przepróbkowaniem (*resampling*).

Przepróbkowanie można wykonać:

1. Z większej rozdzielczości do mniejszej, np. 100 m -> 500 m
(*downsampling*, *downscaling*).
2. Z mnieszej rozdzielczości do większej, np. 500 m -> 100 m
(*upsampling*, *upscaling*).

Z racji iż proste metody przepróbkowania nie zwiększają ilości informacji przy
zwiększaniu rozdzielczości przestrzennej, to lepiej wykonać przepróbkowanie do
niższej rozdzielczości.

Przepróbkowanie w **terra** można wykonać przy pomocy funkcji `resample()`.
Dostępne są różne metody przepróbkowania, ale w przypadku danych kategorycznych,
koniecznie trzeba wykorzystać algorytm najbliższego sąsiada (`method = "near"`)
lub wartość modalną, dominantę (`method = "mode"`). Jeśli tego nie zrobimy,
to ID kategorii zostaną zmienione.

```{r}
cat = resample(cat, landsat, method = "near")
res(cat) # wyświetl rozdzielczość po przepróbkowaniu
```

Kolejne operacje (czyli przycinanie, maskowanie, skalowanie i usunięcie wartości
odstających) przebiegają tak jak w poprzednim przykładzie.

```{r}
# przycinanie, maskowanie
landsat = crop(landsat, poly, mask = TRUE)
cat = crop(cat, poly, mask = TRUE)

# skalowanie
landsat = landsat * 2.75e-05 - 0.2

# usunięcie wartości odstających
landsat[landsat < 0] = NA
landsat[landsat > 1] = NA
```

## Przygotowanie danych

Teraz przygotujmy nasze dane do klasyfikacji. Tym razem użyjemy modelu [drzewa
decyzyjnego](https://www.statsoft.pl/textbook/stclatre.html), który wymaga danych
w postaci ramki danych (*data frame*). Jedna kolumna to zmienna modelowana/zależna
(u nas klasy pokrycia terenu), a pozostałe kolumny to zmienne wyjaśniające/niezależne
(kanały spektralne).

```{r}
data = cbind(values(cat), values(landsat)) # połączenie kolumn w macierzy
data = as.data.frame(data) # konwersja macierzy do ramki danych
data = na.omit(data) # usunięcie brakujących wartości
```

Jedna z klas w zbiorze danych to chmury, które zostały sklasyfikowane podczas
tworzenia mapy z klasami pokrycia terenu. Wiadomo, że zachmurzenie jest zmienne
w czasie, dlatego powinniśmy usunąć tę klasę (`ID = 0`).

```{r}
# usuń piksele reprezentujące klasę chmury
# ! to operator negacji (NOT)
data = data[!data$S2GLC_T33UXT == 0, ]
```

W celu ułatwienia analizy danych, możemy zmienić ID klasy na nazwę.
Dopasowanie nazw klas do ID można wykonać za pomocą funkcji `merge()`.
Dodatkowo, zmieńmy jeszcze nazwę kolumny z `S2GLC_T33UXT` na `klasa`.

```{r}
data = merge(data, leg[, -2], by.x = "S2GLC_T33UXT", by.y = "ID")
data = data[, -1] # usuń pierwszą kolumnę z ID klasy
colnames(data)[8] = "klasa" # zmień nazwę kolumny
data$klasa = as.factor(data$klasa) # zmień typ danych na kategoryczny
```

Dane wejściowe wyglądają teraz następująco.

```{r}
head(data)
```

Przed klasyfikacją warto sprawdzić częstość występowania poszczególnych kategorii.
Jeśli część kategorii pojawia się bardzo często, a niektóre prawie wcale, to wtedy
mamy problem z niezbalansowanym zbiorem danych. W takiej sytuacji, kiedy model
posiada zbyt mało przykładów którejś klasy (np. bagna), to nie jest możliwe żeby
nauczył się rozpoznawać tę klasę. Oprócz tego, wynik jakości klasyfikatora jest
zbyt optymistyczny (tzn. w rzeczywistości działa gorzej niż na zbiorze uczącym).

Częstość występowania klas można sprawdzić za pomocą funkcji `table()` na kolumnie
kategorycznej i następnie zamienić to na postać procentową używając `prop.table()`.

```{r}
tabela = table(data$klasa)
prop.table(tabela) * 100
```

## Klasyfikacja

```{r}
# install.packages(c("rpart", "rpart.plot"))
library("rpart") # model klasyfikacyjny
library("rpart.plot") # wizualizacja modelu
```

Każdy opracowany model powinien zostać poddany walidacji (weryfikacji) na
niezależnym zbiorze danych. Oznacza to, że powinniśmy sprawdzić poprawność
prognozowania naszego modelu na innym zbiorze danych, który nie został wykorzystany
na etapie modelowania (uczenia). Innymi słowy, chcemy wykluczyć sytuację, w której
nasz model mógłby nauczyć się jednie klasyfikować obiekty na naszym obszarze analizy,
a zwracałby błędne wyniki na innym (lecz podobnym) obszarze.

Istnieje wiele metod walidacji, ale wykorzystamy tutaj najprostszą polegającą na
podziale wejściowego zbioru danych na treningowy oraz testowy. Generalnie przyjmuje
się, że proporcja między tymi dwoma zestawami powinna wynosić około 70-80% do
30-20%. Tak jak poprzednio musimy wylosować próbę o ustalonej wielkości używając
funkcji `sample()`.

```{r}
# podział na zbiór treningowy i testowy
set.seed(1) # ziarno losowości
n = round(0.7 * nrow(data)) # wielkość próby 70%
trainIndex = sample(nrow(data), size = n) # wylosuj indeksy
train = data[trainIndex, ] # wybierz próbki treningowe
test = data[-trainIndex, ] # wybierz próbki testowe (nietreningowe)
```

Po tej czynności dochodzimy do najważniejszego etapu, czyli trenowania modelu
klasyfikacyjnego. W tym celu wykorzystamy funkcję `rpart()`, która wymaga
zdefiniowania:

1. Zmiennej zależnej i zmiennych zależnych za pomocą odpowiedniej formuły.
2. Zbioru danych treningowych (`data = train`).
3. Metody (`method = "class"`).

Odnośnie punkty pierwszego, formułę można zdefiniować na dwa sposoby:

1. Używając nazw poszczególnych zmiennych: `klasa ~ B1 + B2 + B3 + B4 + B5 + B6 + B7`.
2. Używając kropki: `klasa ~ .`. Kropka zastępuje wszystkie nazwy zmiennych
wyjaśniających z ramki danych.

Znak `~` (tylda) oznacza "jest zależne od", czyli *klasa pokrycia terenu jest
zależna od kanałów B1 do B7*.

```{r}
mdl = rpart(klasa ~ ., data = train, method = "class")
```

Po zakończeniu tej operacji możemy sprawdzić jakich reguł klasyfikacyjnych
nauczył się model. Drzewo decyzyjne można zwizualizować za pomocą funkcji `prp()`.

```{r}
prp(mdl)
```

Kluczowym etapem modelowania jest walidacja modelu. Sprawdźmy zatem jaka jest
jego skuteczność. W tym celu musimy wykonać predykcję dla zbioru testowego
(funkcja `predict()`). Zbiór danych testowych musi posiadać dokładnie te same
zmienne wyjaśniające co zbiór treningowy. Kolumnę z prawdziwymi (rzeczywistymi)
klasami należy usunąć.

```{r}
# walidacja dla zbioru testowego
pred = predict(mdl, test[, -8], type = "class")
unname(head(pred)) # `unname()` usuwa numer porządkowy wiersza/piksela
```

Wykonaliśmy predykcje dla zbioru testowego. Teraz musimy obliczyć wybraną
miarę skuteczności. Jako przykład wybierzemy dokładność (*accuracy*) definiowaną
jako iloraz poprawnych klasyfikacji do wszystkich (poprawnych i niepoprawnych)
klasyfikacji.

```{r}
pop_klas = test$klasa == pred # zwraca wartość logiczną czy klasa jest prawidłowa
sum(pop_klas) / length(pop_klas)
```

Skuteczność naszego modelu wynosi około 71%. Oprócz jednej ogólnej statystyki
możemy sprawdzić również błędy klasyfikacji dla poszczególnych klas. Takie
zestawienie nazywane jest tabelą pomyłek (*confusion matrix*).

```{r}
table(pred = pred, true = test$klasa)
```

Poprawnie sklasyfikowane obiekty znajdują się na przekątnej. Obiekty sklasyfikowane
jako fałszywe pozytywne (*false positive*) znajdują się w prawej górnej części,
natomiast obiekty sklasyfikowane jako fałszywe negatywne (*false negative*) w
lewej dolnej części.

Jeśli opracowany model spełnia nasze oczekiwania, to możemy wykorzystać go do
predykcji na całym obszarze. Ponownie wykorzystamy funkcję `predict()`, ale tym
razem jako dane wejściowe użyjemy nasz raster `landsat`. Dodatkowo, powinniśmy
ustawić argument `na.rm = TRUE`, aby uniknąć predykcji poza obszarem analizy.

```{r}
pred_map = predict(landsat, mdl, type = "class", na.rm = TRUE)
```

Jako wynik powyższej operacji otrzymaliśmy mapę z predykcją klas pokrycia terenu.
Teraz możemy dokonać wizualizacji. Jednak tym razem musimy użyć odpowiedniego
schematu kolorów, który znajduje się w obiekcie `leg`. Tę operację należy wykonać
w dwóch krokach:

1. Sprawdzić, które klasy rzeczywiście występują na naszym obszarze.
2. Dopasować kolory do odpowiednich klas.

Odnośnie pierwszego punktu, to najprościej wykorzystać funkcję `droplevels()`,
która usunie puste kategorie z rastra (np. winnica, wrzosowisko). Następnie
należy wyświetlić kategorie za pomocą funkcji `levels()`. Do każdej warstwy rastra
mogą być przypisane różne kategorie, więc musimy pobrać je tylko dla pierwszej
warstwy oraz wskazać atrybut `class`.

Dopasowania kolorów można dokonać za pomocą funkcji `match()`. Jako pierwszy
wskazujemy obiekt z naszymi klasami, jako drugi obiekt ramkę danych ze schematem
kolorów (`leg`) i w wyniku otrzymamy dopasowane indeksy kolorów.

```{r}
lv = droplevels(pred_map) # usuń puste kategorie z rastra
lv = levels(lv) # zwróć kategorie jako ramkę danych
lv = lv[[1]][["class"]] # wybierz pierwszą warstwę i kolumnę z nazwami klas
```

```{r}
col_idx = match(lv, leg$Klasa) # dopasuj klasy do odpowiednich kolorów
plot(pred_map, main = "Predykcja klas", col = leg$RGB[col_idx])
```

W przypadku, gdy raster posiada oryginalne ID klas (tj. 0, 62, 73, 75, itd.),
to możemy po prostu przypisać ramkę danych do rastra.

```{r}
levels(cat) = leg[, c(1, 3)]
lv = levels(droplevels(cat))[[1]][["Klasa"]]
col_idx = match(lv, leg$Klasa)
plot(cat, col = leg$RGB[col_idx], main = "Rzeczywiste klasy")
```

## Podsumowanie

Niniejsze warsztaty stanowią jedynie zarys wykorzystania metod uczenia maszynowego
do analizy danych przestrzennych. Oprócz problemu klasyfikacji możemy również
rozwiązywać problemy z zakresu regresji, wykrywania anomalii, redukcji wymiarowości,
itd., używając bardziej zaawansowanych modeli (np. lasy losowe, modele wzmacnianie,
sieci neuronowe, uczenie głębokie).

Co więcej, cała analiza może być bardziej zaawansowana. Przedstawione treści
można rozwinąć o kolejne zagadnienia dotyczące:

- automatycznego wyszukiwania i pobierania danych satelitarnych,
- integracji różnych sensorów (satelity + drony),
- przetwarzania danych w chmurze,
- optymalizacji parametrów modeli,
- innych metod walidacji wyników (w tym ujęciu przestrzennym),
- oceny istotności zmiennych wyjaśniających.

Należy podkreślić, że zdjęcia satelitarne to nie jest jedyne źródło danych
przestrzennych i do analizy można wykorzystać zupełnie inne dane, np.
cyfrowe modele wysokościowe czy zasięgi występowania gatunków.

Jeśli zainteresowałeś się tym tematem, to jego rozwinięcie znajdziesz w poniższych
podręcznikach (W j. angielskim):

- [**Spatial Data Science with R and “terra”**](https://rspatial.org/terra/)
- [Geocomputation with R](https://geocompr.robinlovelace.net/)
- [Spatial Data Science, with applications in R](https://r-spatial.org/book/)

Warto również sprawdzić inne pakiety do [analizy danych przestrzennych](https://cran.r-project.org/web/views/Spatial.html)
oraz [uczenia maszynowego](https://cran.r-project.org/web/views/MachineLearning.html).

W razie problemów pomoc najlepiej szukać na [StackOverflow](https://stackoverflow.com/),
lub [RStudio Community](https://community.rstudio.com/). Często ciekawe dyskusje
pojawiają się na Twitterze ([#rspatial](https://twitter.com/hashtag/rspatial)) 
oraz GitHubie (https://github.com/rspatial; https://github.com/r-spatial).
